{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96374c1a-fcba-46a1-af9e-33d34d8560c5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Feature Engineering\n",
    "\n",
    "For some definitions, handling outliers and missing values, scaling, and encoding may be considered feature engineering. Here we'll draw a distinction between data preparation, data preprocessing, and feature engineering.\n",
    "\n",
    "- **Data preparation**: the basic data cleaning necessary to get our data ready for exploration/analysis, e.g. correcting data types, fixing typos\n",
    "- **Data preprocessing**: further data transformation done for the sake of modeling, as oppsoed to exploration/analysis, e.g. scaling, imputing, encoding\n",
    "- **Feature engineering**: adding, combining, or removing features; usually with the help of domain knowledge\n",
    "\n",
    "Feature engineering can happen as part of data exploration or modeling, and engineered featured are also commonly explored."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0129d56",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Some examples of feature engineering by this definition:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10038b9a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "- Domain-based conversion (example: fahrenheit to celsius, BMI calculation, log transformation)\n",
    "- Domain based cutoffs (example: `age >= 18 = is_adult`; also dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd20c31",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "- Add / subtract (example: zillow dataset: beds + baths = room_count; total_sqft - 200 * bedrooms - 40 * bathrooms = living_area)\n",
    "- Combine as booleans as a count (example: telco_churn: streaming + backups + ...  = service_count)\n",
    "- Multiply / divide (example: tips dataset: total_bill / size = price_per_person)\n",
    "- Ratios (example: tips dataset: tip / total_bill = tip percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641f264d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Simplify!\n",
    "\n",
    "- Categorical with many unique values to top 3 + \"Other\"\n",
    "- Categorical to boolean: pool count -> has pool\n",
    "- Continous -> categorical via binning (aka quantization or discretization) (example: income -> high, medium, low earner)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4104eb-91b5-4168-b53f-2a11597bfacb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "In this lesson we'll cover some *automated* **feature selection** methods, that is, methods for determining which features are the most important.\n",
    "\n",
    "Feature selection can be broken down into supervised and unsupervised methods. And supervised methods can be broken down into intrinsic, filter, and wrapper methods.\n",
    "- **Supervised:** Remove irrelevant variables\n",
    "    - <u>Intrinsic</u>: Algorithms that perform automatic feature selection during training.\n",
    "    - <u>Filter</u>: Select subsets of features based on their relationship with the target.\n",
    "    - <u>Wrapper</u>: Search subsets of features that perform according to a predictive model.\n",
    "\n",
    "\n",
    "- **Unsupervised:** Remove redundant variables\n",
    "\n",
    "\n",
    "Methods Reviewed in this lesson:\n",
    "- SelectKBest \n",
    "- Recursive Feature Elimination \n",
    "- Sequential Feature Selection "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed3a33a-2ca3-4625-94fd-def89bb5b497",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7018acce-d54f-4f9c-b9b8-ee2658d22d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectKBest, RFE, f_regression, SequentialFeatureSelector\n",
    "from sklearn.model_selection import train_test_split\n",
    "import wrangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8a3744",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrangle_grades():\n",
    "    '''\n",
    "    Read student_grades csv file into a pandas DataFrame,\n",
    "    drop student_id column, replace whitespaces with NaN values,\n",
    "    drop any rows with Null values, convert all columns to int64,\n",
    "    return cleaned student grades DataFrame.\n",
    "    '''\n",
    "    # Acquire data from csv file.\n",
    "    file = \"https://gist.githubusercontent.com/ryanorsinger/14c8f919920e111f53c6d2c3a3af7e70/raw/07f6e8004fa171638d6d599cfbf0513f6f60b9e8/student_grades.csv\"\n",
    "\n",
    "    grades = pd.read_csv(file)\n",
    "\n",
    "    # Replace white space values with NaN values.\n",
    "    grades = grades.replace(r'^\\s*$', np.nan, regex=True)\n",
    "\n",
    "    # Drop all rows with NaN values.\n",
    "    df = grades.dropna()\n",
    "\n",
    "    # Convert all columns to int64 data types.\n",
    "    df = df.astype('int')\n",
    "\n",
    "    # drop student_id\n",
    "    df = df.drop(columns=['student_id'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb0b3d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = wrangle_grades()\n",
    "train_validate, test = train_test_split(df, random_state=123, train_size=.8)\n",
    "train, validate = train_test_split(train_validate, random_state=123, train_size=.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e04261f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape, validate.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59534ad5-8a6b-438f-b294-079988191ad2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = train[['exam1', 'exam2', 'exam3']]\n",
    "y_train = train.final_grade\n",
    "X_validate = validate[['exam1', 'exam2', 'exam3']]\n",
    "y_validate = validate.final_grade\n",
    "X_test = test[['exam1', 'exam2', 'exam3']]\n",
    "y_test = test.final_grade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc4ebee-12bc-432e-9631-e6c8adb10021",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Select K Best\n",
    "\n",
    "- looks at each feature in isolation against the target based on correlation\n",
    "- fastest of all approaches covered in this lesson\n",
    "- doesn't consider feature interactions\n",
    "- After fitting: `.scores_`, `.pvalues_`, `.get_support()`, and `.transform`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196e7dee-3665-4d14-9843-fc3c4c6a16d4",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Like our other sklearn objects...\n",
    "kbest = SelectKBest(f_regression, k=2)\n",
    "kbest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a07efc0-17e9-4b79-ba03-058c08fbcbcd",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "kbest_results = pd.DataFrame(dict(p=kbest.pvalues_, f=kbest.scores_), index=X_train.columns)\n",
    "kbest_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18824290-e7ff-4213-84d1-8969f63e9aa2",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "X_train.columns[kbest.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad85c8bc-e398-494a-9598-caad999564f9",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "X_train_transformed = pd.DataFrame(\n",
    "    kbest.transform(X_train),\n",
    "    index=X_train.index,\n",
    "    columns=X_train.columns[kbest.get_support()]\n",
    ")\n",
    "X_train_transformed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a5069f-d6d6-49c4-aa81-76fdb806198b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## RFE\n",
    "\n",
    "- Recursive Feature Elimination\n",
    "- Progressively eliminate features based on importance to the model\n",
    "- Requires a model with either a `.coef_` or `.feature_importances_` property\n",
    "- After fitting: `.ranking_`, `.get_support()`, and `.transform()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9c3953-6a49-466d-90b9-188429346832",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b23b48c-b13f-4f9c-b0f0-6d24f5ccc9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "rfe = RFE(model, n_features_to_select=2)\n",
    "rfe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc031df-50ac-4767-92ad-a8b67fa39639",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({'rfe_ranking': rfe.ranking_}, index=X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a00846-fdd4-44b6-868c-2a183509d00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns[rfe.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f386c9f6-bc2e-488f-9e8f-63d29367ad6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed = pd.DataFrame(\n",
    "    rfe.transform(X_train),\n",
    "    index=X_train.index,\n",
    "    columns=X_train.columns[rfe.support_]\n",
    ")\n",
    "X_train_transformed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8d6e09-dab8-47d1-b7f4-8afca62d9d8c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sequential Feature Selector\n",
    "\n",
    "- progressively adds features based on cross validated model performance\n",
    "- forwards: start with 0, add the best additional feature until you have the desired number\n",
    "- backwards: start with all features, remove the worst performing until you have the desired number\n",
    "- After fitting: `.support_`, `.transform`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6d0453-7ada-4b12-a9bd-09326ba9360e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "sfs = SequentialFeatureSelector(model, n_features_to_select=2, scoring='neg_mean_absolute_error', direction='backward')\n",
    "sfs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78019029-0d7f-4bbc-b2b1-921b78cbde0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed = pd.DataFrame(\n",
    "    sfs.transform(X_train),\n",
    "    index=X_train.index,\n",
    "    columns=X_train.columns[sfs.support_]\n",
    ")\n",
    "X_train_transformed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59d1a9a-9fa4-4c08-9680-c40300dcb5b5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "- Simpler models handle change + variability better\n",
    "- Use RFE to narrow down your features and find the best ones, if your dataset is large (> 1GB; `df.info()`) use select k best instead\n",
    "- Remember: feature engineering is much more than feature selection!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9f2158",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "rise": {
   "enable_chalkboard": true,
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
